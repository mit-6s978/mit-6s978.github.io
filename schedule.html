<!DOCTYPE html
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>MIT 6.S978: Deep Generative Models, Fall 2024</title>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
    <link href="assets/css/style.css" rel="stylesheet" type="text/css" />

    <link rel="icon" href="assets/img/icon.png" sizes="32x32" />
    <link rel="icon" href="assets/img/icon.png" sizes="192x192" />
</head>

<body>

    <div class="container">
        <table border="0" align="center">
            <tr>
                <td width="623" align="center" valign="middle">
                    <span class="title">6.S978 Deep Generative Models</span>
                    <h3>MIT EECS, Fall 2024</h3>
                </td>
            </tr>
        </table>
        <br>
        <br>
        <p>This schedule is preliminary and subject to change as the term
            evolves.</p>
        <br>
        <table class="schedule" align="center" border="1" width="986">
            <tbody>
                <tr>
                    <td align="center" width="103"><strong>Date</strong></td>
                    <td align="center" width="232"><strong>Topics</strong></td>
                    <td align="center" width="250"><strong>Course Materials</strong></td>
                    <td align="center" width="120"><strong>Assignments</strong></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 1</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 09/05/2024</td>
                    <td align="left"><b style='color:#F7941D;'>Lecture</b><b>: Introduction</b></td>
                    <td align="center">
                        <p align="center"><img class="teaser" src="assets/img/lec1_intro.jpg" height="160"
                                align="middle" /></p>
                        <a href="assets/pdfs/lec1_intro.pdf">slides</a>
                    </td>
                    <td>
                    </td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 2</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 09/10/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Modeling Image Prior</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                D. Zoran and Y. Weiss, From Learning Models of Natural Image Patches to Whole Image
                                Restoration,
                                ICCV 2011
                                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6126278">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                D. Zoran and Y. Weiss, Natural Images, Gaussian Mixtures and Dead Leaves, NeurIPS 2012
                                <a
                                    href="https://proceedings.neurips.cc/paper_files/paper/2012/file/e97ee2054defb209c35fe4dc94599061-Paper.pdf">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                D. Ulyanov et al., Deep Image Prior, CVPR 2018
                                <a
                                    href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Ulyanov_Deep_Image_Prior_CVPR_2018_paper.pdf">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                        <b>(Optional) Recommended readings:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                A. A. Efros and T. K. Leung, Texture Synthesis by Non-parametric Sampling, 1999
                                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=790383">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                C. Barnes et al., PatchMatch: A Randomized Correspondence Algorithm for
                                Structural
                                Image Editing, 2009
                                <a href="https://3dvar.com/Barnes2009PatchMatch.pdf">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                W. T. Freeman et al., Example-Based Super-Resolution, 2002
                                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=988747">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td><a href="https://drive.google.com/drive/folders/18ApUM-i2h5AVDQu7zYmMvKlZH5I3vy1I?usp=sharing">Assignment
                            #1</a></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 09/12/2024</td>
                    <td align="left"><b style='color:#F7941D;'>Lecture</b><b>: Variational Autoencoder (VAE)</b></td>
                    <td align="center">
                        <p align="center"><img class="teaser" src="assets/img/lec2_vae.jpg" height="160"
                                align="middle" /></p>
                        <a href="assets/pdfs/lec2_vae.pdf">slides</a>
                    </td>
                    <td></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 3</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 09/17/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Normalizing Flows</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                D. Rezende and S. Mohamed,
                                Variational Inference with Normalizing Flows,
                                ICML 2015
                                <a href="https://proceedings.mlr.press/v37/rezende15">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                D. P. Kingma and P. Dhariwal, Natural Images, Glow: Generative Flow with Invertible 1x1
                                Convolutions, NeurIPS 2018
                                <a
                                    href="https://proceedings.neurips.cc/paper_files/paper/2018/hash/d139db6a236200b21cc7f752979132d0-Abstract.html">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                J. Behrmann et al., Invertible residual networks, ICML 2019
                                <a href="https://proceedings.mlr.press/v97/behrmann19a.html?ref=https://githubhelp.com">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                        <b>(Optional) Recommended readings:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                Lilian Weng's post on "Flow-based Deep Generative Models"
                                <a href="https://lilianweng.github.io/posts/2018-10-13-flow-models/">
                                    [Link]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 09/19/2024</td>
                    <td align="left"><b style='color:#F7941D;'>Lecture</b><b>: Autoregressive (AR) Models</b></td>
                    <td align="center">
                        <p align="center"><img class="teaser" src="assets/img/lec3_ar.jpg" height="160"
                                align="middle" /></p>
                        <a href="assets/pdfs/lec3_ar.pdf">slides</a>
                    </td>
                    <td></td>

                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 4</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 09/24/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Autoregressive (AR) Models</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                Y. Bengio and S. Bengio,
                                Modeling High-Dimensional Discrete Data with Multi-Layer Neural Networks,
                                NIPS 1999
                                <a
                                    href="https://proceedings.neurips.cc/paper_files/paper/1999/file/e6384711491713d29bc63fc5eeb5ba4f-Paper.pdf">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                A. Van Den Oord et al., Pixel Recurrent Neural Networks, ICML 2016
                                <a href="https://proceedings.mlr.press/v48/oord16.pdf">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                D. P. Kingma et al., Improved Variational Inference with Inverse Autoregressive Flow,
                                NIPS 2016
                                <a
                                    href="https://proceedings.neurips.cc/paper_files/paper/2016/file/ddeebdeefdb7e7e7a697e1c3e3d8ef54-Paper.pdf">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td><b>Assignment #1 Due</b> <br> <a
                            href="https://drive.google.com/drive/folders/1a7nFsrYK-VlA3NwecXjN2Fp2OU-E4nJw?usp=sharing">Assignment
                            #2</a></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 09/26/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: AR and tokenizers</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                L. Yu et al.,
                                Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation,
                                ICLR 2024
                                <a href="https://arxiv.org/abs/2310.05737">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                K. Tian et al., Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale
                                Prediction, arXiv
                                <a href="https://arxiv.org/abs/2404.02905">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                Q. Yu et al., An Image is Worth 32 Tokens for Reconstruction and Generation, arXiv
                                <a href="https://arxiv.org/abs/2406.07550">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                        <b>(Optional) Recommended readings:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                M. Chen et al., Generative Pretraining from Pixels, ICML 2020
                                <a href="https://proceedings.mlr.press/v119/chen20s/chen20s.pdf">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                A. Ramesh et al., Zero-Shot Text-to-Image Generation (DALLE1), ICML 2021
                                <a href="https://arxiv.org/pdf/2102.12092">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                F. Mentzer et al., Finite Scalar Quantization: VQ-VAE Made Simple, arXiv
                                <a href="https://arxiv.org/abs/2309.15505">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 5</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 10/01/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: AR and Diffusion</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                T. Li et al.,
                                Autoregressive Image Generation without Vector Quantization,
                                arXiv
                                <a href="https://arxiv.org/abs/2406.11838">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                C. Zhou et al., Transfusion: Predict the Next Token and Diffuse Images with One
                                Multi-Modal Model, arXiv
                                <a href="https://www.arxiv.org/abs/2408.11039">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                J. Xie et al., Show-o: One Single Transformer to Unify Multimodal Understanding and
                                Generation,
                                arXiv
                                <a href="https://arxiv.org/abs/2408.12528">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>

                        <b>(Optional) Recommended readings:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                E. Hoogeboom et al., Autoregressive Diffusion Models, ICLR 2022
                                <a href="https://arxiv.org/abs/2110.02037">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                B. Chen et al., Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion,
                                arXiv
                                <a href="https://arxiv.org/abs/2407.01392">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 10/03/2024</td>
                    <td align="left"><b style='color:#F7941D;'>Lecture</b><b>: Generative Adversarial Network (GAN)</b>
                    <td align="center">
                        <p align="center"><img class="teaser" src="assets/img/lec4_gan.jpg" height="160"
                                align="middle" /></p>
                        <a href="assets/pdfs/lec4_gan.pdf">slides</a>
                    </td>
                    <td></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 6</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 10/08/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: GAN in the era of diffusion</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                A. Sauer et al.,
                                StyleGAN-T- Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis,
                                ICML 2023
                                <a href="https://arxiv.org/abs/2301.09515">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                M. Kang et al., Scaling up GANs for Text-to-Image Synthesis, CVPR 2023
                                <a href="https://arxiv.org/abs/2303.05511">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                M. Kang et al., Distilling Diffusion Models into Conditional GANs,
                                ECCV 2024
                                <a href="https://arxiv.org/abs/2405.05967">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td><b>Assignment #2 Due</b> <br> <a
                            href="https://drive.google.com/drive/folders/18dWKJYv2vXQ5VKV8kMqTwDJBWIe6O7PU?usp=sharing">Assignment
                            #3</a></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 10/10/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: GAN in the era of Diffusion</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                N. Huang et al.,
                                The GAN is dead; long live the GAN! A Modern GAN Baseline,
                                ICML 2024
                                <a href="https://openreview.net/pdf/9197a4074900f763675c3c896d7c4ca3402a3c55.pdf">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                Z. Wang et al., Diffusion-GAN: Training GANs with Diffusion, ICLR 2023
                                <a href="https://arxiv.org/abs/2206.02262">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                S. Asokan et al., GANs Settle Scores!,
                                arXiv
                                <a href="https://arxiv.org/abs/2306.01654">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 7</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 10/15/2024</td>
                    <td align="left"><b>No class (student holiday)</b> </td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 10/17/2024</td>
                    <td align="left"><b style='color:#F7941D;'>Lecture</b><b>: Energy-based Models, Score matching,
                            Diffusion Models</b></td>
                    <td align="center">
                        <p align="center"><img class="teaser" src="assets/img/lec5_diffusion.jpg" height="160"
                                align="middle" /></p>
                        <a href="assets/pdfs/lec5_diffusion.pdf">slides</a>
                    </td>
                    <td>
                    </td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 8</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 10/22/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Diffusion Models</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                J. Ho and T. Salimans,
                                Classifier-Free Diffusion Guidance,
                                NeurIPS 2021
                                <a href="https://arxiv.org/abs/2207.12598">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                T. Salimans and J. Ho,
                                Progressive Distillation for Fast Sampling of Diffusion Models, ICLR 2022
                                <a href="https://arxiv.org/abs/2202.00512">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                E. Hoogeboom et al.,
                                Simple diffusion: End-to-end diffusion for high resolution images,
                                ICML 2023
                                <a href="https://arxiv.org/abs/2301.11093">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>

                        <b>(Optional) Recommended readings:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                R. Rombach et al., High-Resolution Image Synthesis with Latent Diffusion Models, CVPR
                                2022
                                <a href="https://arxiv.org/abs/2112.10752">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                T. Karras et al., Elucidating the Design Space of Diffusion-Based Generative Models,
                                NeurIPS 2022
                                <a href="https://arxiv.org/abs/2206.00364">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                A. Ramesh et al., Hierarchical Text-Conditional Image Generation with CLIP Latents,
                                arXiv
                                <a href="https://arxiv.org/abs/2204.06125">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                T. Chen, On the Importance of Noise Scheduling for Diffusion Models,
                                arXiv
                                <a href="https://arxiv.org/pdf/2301.10972">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                Sander Dieleman's post on "Diffusion is spectral autoregression"
                                <a href="https://sander.ai/2024/09/02/spectral-autoregression.html">
                                    [Link]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td><b>Assignment #3 Due</b> <br> <a
                            href="https://drive.google.com/drive/folders/1eY4KrD4Q5f4CIAUWWDbo_Zp1Qrv3Dfea?usp=sharing">Assignment
                            #4</a></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 10/24/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Diffusion beyond Denoising</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                A. Bansal et al.,
                                Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise,
                                NeurIPS 2023
                                <a href="https://arxiv.org/abs/2208.09392">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                S. Rissanen et al.,
                                Generative Modelling With Inverse Heat Dissipation, ICLR 2023
                                <a href="https://arxiv.org/abs/2206.13397">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                M. Delbracio et al.,
                                Inversion by Direct Iteration- An Alternative to Denoising Diffusion for Image
                                Restoration,
                                TMLR 2023
                                <a href="https://arxiv.org/abs/2303.11435">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>

                        <b>(Optional) Recommended readings:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                G. Daras et al., Soft Diffusion: Score Matching for General Corruptions, TMLR 2023
                                <a href="https://arxiv.org/abs/2209.05442">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 9</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 10/29/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Discrete Diffusion</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                J. Austin et al.,
                                Structured Denoising Diffusion Models in Discrete State-Spaces,
                                NeurIPS 2021
                                <a href="https://arxiv.org/abs/2107.03006">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                S. Gong et al.,
                                DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models, ICLR 2023
                                <a href="https://arxiv.org/abs/2210.08933">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                A. Lou et al.,
                                Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution,
                                ICML 2024
                                <a href="https://arxiv.org/abs/2310.16834">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 10/31/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Flow Matching 1</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                Y. Lipman et al.,
                                Flow Matching for Generative Modeling,
                                ICLR 2023
                                <a href="https://arxiv.org/abs/2210.02747">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                M. S. Albergo et al.,
                                Building Normalizing Flows with Stochastic Interpolants, ICLR 2023
                                <a href="https://arxiv.org/abs/2209.15571">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                X. Liu et al.,
                                Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow,
                                ICLR 2023
                                <a href="https://arxiv.org/abs/2209.03003">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>

                        <b>(Optional) Recommended readings:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                Post on "An Introduction to Flow Matching"
                                <a
                                    href="https://mlg.eng.cam.ac.uk/blog/2024/01/20/flow-matching.html#figure-forward_samples-one-color-1">
                                    [Link]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 10</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 11/05/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Flow Matching 2</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                P. Esser et al.,
                                Scaling Rectified Flow Transformers for High-Resolution Image Synthesis,
                                ICML 2024
                                <a href="https://arxiv.org/abs/2403.03206">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                N. Ma et al.,
                                SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant
                                Transformers, ECCV 2024
                                <a href="https://arxiv.org/abs/2401.08740">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                I. Gat et al.,
                                Discrete Flow Matching,
                                arXiv
                                <a href="https://arxiv.org/abs/2407.15595">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td><b>Assignment #4 Due</b> <br> <a href="">Assignment #5</a></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 11/07/2024</td>
                    <td align="left"><b style='color:#F7941D;'>Guest Lecture</b><b>: <a style='color:#F7941D;'
                                href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a> - Ensuring Data Ownership in
                            Generative Models</b></td>
                    <td align="left">
                    </td>
                    <td></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 11</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 11/12/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Application - Videos</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                O. Bar-Tal et al.,
                                Lumiere: A Space-Time Diffusion Model for Video Generation,
                                arXiv
                                <a href="https://arxiv.org/abs/2401.12945">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                J. Bruce et al.,
                                Genie: Generative Interactive Environments, arXiv
                                <a href="https://arxiv.org/abs/2402.15391">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                The Movie Gen team @ Meta,
                                Movie Gen: A Cast of Media Foundation Models,
                                arXiv
                                <a href="https://ai.meta.com/static-resource/movie-gen-research-paper">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 11/14/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Application - 3D and Geometry</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                B. Poole et al.,
                                DreamFusion: Text-to-3D using 2D Diffusion,
                                ICLR 2023
                                <a href="https://arxiv.org/abs/2209.14988">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                Y. Hong et al.,
                                LRM: Large Reconstruction Model for Single Image to 3D, ICLR 2024
                                <a href="https://arxiv.org/abs/2311.04400">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                Y. Siddiqui et al.,
                                MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers,
                                CVPR 2024
                                <a href="https://nihalsid.github.io/mesh-gpt/">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>

                        <b>(Optional) Recommended readings:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                L. Zhang et al., CLAY: A Controllable Large-scale Generative Model for Creating
                                High-quality 3D Assets, SIGGRAPH 2024
                                <a href="https://arxiv.org/abs/2406.13897">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                X. Wei et al., MeshLRM: Large Reconstruction Model for High-Quality Meshes, arXiv
                                <a href="https://sarahweiii.github.io/meshlrm/">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                T. Shen et al., Flexible Isosurface Extraction for Gradient-Based Mesh Optimization,
                                SIGGRAPH 2023
                                <a href="https://research.nvidia.com/labs/toronto-ai/flexicubes/">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 12</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 11/19/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Application - Robotics</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                M. Janner et al.,
                                Planning with Diffusion for Flexible Behavior Synthesis,
                                ICML 2022
                                <a href="https://arxiv.org/abs/2205.09991">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                C. Chi et al.,
                                Diffusion Policy: Visuomotor Policy Learning via Action Diffusion, RSS 2023
                                <a href="https://arxiv.org/abs/2303.04137">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                S. Yang et al.,
                                UniSim: Learning Interactive Real-World Simulators,
                                ICLR 2024
                                <a href="https://arxiv.org/abs/2310.06114">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>

                        <b>(Optional) Recommended readings:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                D. Driess et al., PaLM-E: An Embodied Multimodal Language Model, ICML 2023
                                <a href="https://arxiv.org/abs/2303.03378">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td><b>Assignment #5 Due</b> <br> <a href="">Assignment #6</a></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 11/21/2024</td>
                    <td align="left"><b style='color:#F7941D;'>Guest Lecture</b><b>: <a style='color:#F7941D;'
                                href="https://yang-song.net/">Yang Song</a> - Consistency Models</b></td>
                    <td align="left">
                    </td>
                    <td></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 13</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 11/26/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Application - Material Science</b></td>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                W. Jin et al.,
                                Junction Tree Variational Autoencoder for Molecular Graph Generation,
                                ICML 2018
                                <a href="https://arxiv.org/pdf/1802.04364">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                E. Hoogeboom et al.,
                                Equivariant Diffusion for Molecule Generation in 3D, ICML 2022
                                <a href="https://proceedings.mlr.press/v162/hoogeboom22a">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                G. Zhou et al.,
                                Uni-Mol: A Universal 3D Molecular Representation Learning Framework,
                                ICLR 2023
                                <a href="https://openreview.net/forum?id=6K2RM6wVqKu">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>

                        <b>(Optional) Recommended readings:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                M. Xu et al., Geometric Latent Diffusion Models for 3D Molecule Generation, ICML 2023
                                <a href="https://arxiv.org/abs/2305.01140">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                M. Arts et al., Two for One: Diffusion Models and Force Fields for Coarse-Grained
                                Molecular Dynamics, arXiv
                                <a href="https://arxiv.org/abs/2302.00600">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>
                    </td>
                    <td></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 11/28/2024</td>
                    <td align="left"><b>No class (Thanksgiving)</b> </td>
                    <td></td>
                    <td></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 14</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 12/03/2024</td>
                    <td align="left"><b style='color:#1C75BC;'>Reading</b><b>: Application - Protein and Biology</b>
                    <td align="left">
                        <b>Reading List:</b><br>
                        <ol style="padding-left: 20px;">
                            <li>
                                J. L. Watson et al.,
                                De novo design of protein structure and function with RFdiffusion,
                                Nature
                                <a href="https://www.nature.com/articles/s41586-023-06415-8">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                J. Abramson et al.,
                                Accurate structure prediction of biomolecular interactions with AlphaFold 3, Nature
                                <a href="https://www.nature.com/articles/s41586-024-07487-w">
                                    [PDF]
                                </a><br>
                            </li>
                            <li>
                                J. B. Ingraham et al.,
                                Illuminating protein space with a programmable generative model,
                                Nature
                                <a href="https://www.nature.com/articles/s41586-023-06728-8">
                                    [PDF]
                                </a><br>
                            </li>
                        </ol>

                    <td><b>Assignment #6 Due</b></td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Thurs 12/05/2024</td>
                    <td align="left"><b style='color:#009444;'>Final Presentation 1</b></td>
                    <td align="left">
                    </td>
                    <td></td>
                </tr>

                <tr>
                    <td colspan="6" class="schedule_week" align="center" height="28" valign="middle">Week 15</td>
                </tr>
                <tr>
                    <td sdnum="1033;0;@" align="left">Tues 12/10/2024</td>
                    <td align="left"><b style='color:#009444;'>Final Presentation 2</b></td>
                    <td align="left">
                    </td>
                    <td></td>
                </tr>

            </tbody>
        </table>
        <p>&nbsp;</p>
    </div>

</body>

</html>